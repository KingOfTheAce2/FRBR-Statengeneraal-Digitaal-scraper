name: Scrape Statengeneraal Digitaal OCR

on:
  schedule:
      # every half-hour: at minute 0 and 30 of every hour
      - cron: '*/30 * * * *'

  workflow_dispatch:
    inputs:
      hf_repo:
        description: "Target Hugging Face dataset repo (e.g. username/sgd-ocr)"
        required: true
        default: "vGassen/Dutch-Statengeneraal-Digitaal-Historical"
      private:
        description: "Make the dataset private? (true/false)"
        required: false
        default: "false"

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      HF_TOKEN: ${{ secrets.HF_TOKEN }}          # <-- add this secret in repo settings
      HF_DATASET_REPO: ${{ github.event.inputs.hf_repo || 'vGassen/Dutch-Statengeneraal-Digitaal-Historical' }}
      HF_PRIVATE: ${{ github.event.inputs.private || 'false' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml datasets tqdm

      - name: Restore progress
        uses: actions/cache@v4
        with:
          path: visited.txt
          key: visited-${{ github.run_id }}
          restore-keys: visited-

      - name: Run scraper
        run: python crawler_for_sgd.py --resume
